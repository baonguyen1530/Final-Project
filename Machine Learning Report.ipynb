{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809c8d4f",
   "metadata": {},
   "source": [
    "# Protein Subcellular Localization Prediction: A Machine Learning Approach for Gram-Positive Bacterial Proteins\n",
    "-------------------------------------------------------------------------------------------\n",
    "* By Bao, Cherif, and Lucas Liona\n",
    "* Professor Dehzangi\n",
    "--------------------------------------------------------------------------------------------\n",
    "\n",
    "This is a Jupyter Notebook, this allows us to both show the code/statistics and give our commentary on challenges we faced and how each step impacted our final project\n",
    "\n",
    "# Project Outline\n",
    "* Step 1: Read data and extract relevant features (can be done manually with Occurence and Composition)\n",
    "* Step 2: You will need to prepare the data (properly put them together with labels) and use different ML methods (KNN, SVM, Bayes, ANN, Random Forest).\n",
    "    * This is a multiclass classification problem\n",
    "* Step 3: Analyze and Interpret output\n",
    "    - Independent Test Set\n",
    "    - K-Fold Cross Validation\n",
    "    - Accuracy, Precision, Recall, AUC\n",
    "    - Dicuss Reults and Interprate Output\n",
    "\n",
    "\n",
    "# Step 1: Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619d4b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Step 1: Load the data\n",
    "print(\"reading 3 CSV's...\")\n",
    "g_data = pd.read_csv(\"g_data.csv\", header=None, names=['Class', 'Fold', 'ProteinID', 'Sequence'])  # Protein sequences\n",
    "occur_data = pd.read_csv(\"occur.csv\")  # Occurrence features\n",
    "attributes_data = pd.read_csv(\"attributes.csv\", skiprows=1)  # Physicochemical properties\n",
    "\n",
    "\n",
    "print(\"populating Amino Acid dictionary...\")\n",
    "# Process the attributes data to create a dictionary for easy access\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "attributes_dict = {}\n",
    "\n",
    "# Process each physicochemical property\n",
    "for i in range(1, 10):  # Using first 9 properties for simplicity, can be extended\n",
    "    property_name = attributes_data.iloc[i-1, 1]\n",
    "    property_values = {}\n",
    "    for j, aa in enumerate(amino_acids):\n",
    "        property_values[aa] = float(attributes_data.iloc[i-1, j+2])\n",
    "    attributes_dict[property_name] = property_values\n",
    "\n",
    "print(f\"\\nHere's a preview of what the data looks like:\\n\")\n",
    "\n",
    "print(\"=== ATTRIBUTES DICT === \\n\" + str(attributes_dict) + '\\n')\n",
    "\n",
    "print(\"=== GDATA === \\n\" + str(g_data.head())+ '\\n')\n",
    "print(\"=== OCCUR_DATA === \\n\" + str(occur_data.head())+ '\\n')\n",
    "print(\"=== ATRRIBUTES_DATA === \\n\" + str(attributes_data.head())+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cda09-e112-4f5e-8ca4-5182365329a0",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "This step is pretty simple; we just read the CSV's into panda dataframes (which is essentially a matrix with labeled axes)\n",
    "\n",
    "We also importantly create a Dictionary to store the data from the Attributes CSV, which contains different properties about the molecules. We pay a bit of computation in this step (a really tiny amount iterating through matrix) for easier access later in the program\n",
    "\n",
    "# Step 2: Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595cb8d-81b0-48d0-9da0-415e1e1aa479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amino_acid_composition(sequence):\n",
    "    \"\"\"Calculate amino acid composition (frequencies) in the sequence.\"\"\"\n",
    "    #sequence = extract_sequence(sequence)\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    counts = Counter(sequence)\n",
    "    composition = {aa: counts.get(aa, 0) / len(sequence) for aa in amino_acids}\n",
    "    return composition\n",
    "\n",
    "def dipeptide_composition(sequence):\n",
    "    \"\"\"Calculate dipeptide (2-mer) composition in the sequence.\"\"\"\n",
    "    #sequence = extract_sequence(sequence)\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    dipeptides = [aa1+aa2 for aa1 in amino_acids for aa2 in amino_acids]\n",
    "    \n",
    "    # Count dipeptides\n",
    "    dip_counts = {}\n",
    "    for i in range(len(sequence)-1):\n",
    "        dipeptide = sequence[i:i+2]\n",
    "        if all(aa in amino_acids for aa in dipeptide):\n",
    "            dip_counts[dipeptide] = dip_counts.get(dipeptide, 0) + 1\n",
    "    \n",
    "    # Normalize by total number of dipeptides\n",
    "    total_dipeptides = max(1, len(sequence)-1)  # Avoid division by zero\n",
    "    dip_composition = {dip: dip_counts.get(dip, 0) / total_dipeptides for dip in dipeptides}\n",
    "    return dip_composition\n",
    "\n",
    "def avg_physicochemical_properties(sequence):\n",
    "    \"\"\"Calculate average physicochemical properties for the sequence.\"\"\"\n",
    "    #sequence = extract_sequence(sequence)\n",
    "    properties = {}\n",
    "    \n",
    "    # Calculate average value for each property\n",
    "    for prop_name, prop_values in attributes_dict.items():\n",
    "        avg_value = 0\n",
    "        count = 0\n",
    "        for aa in sequence:\n",
    "            if aa in prop_values:\n",
    "                avg_value += prop_values[aa]\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            avg_value /= count\n",
    "        properties[f\"avg_{prop_name}\"] = avg_value\n",
    "    \n",
    "    return properties\n",
    "\n",
    "# After we define our functione, we apply feature extraction to all sequences by accessing the Sequence Column\n",
    "g_data['aa_features'] = g_data['Sequence'].apply(amino_acid_composition)\n",
    "g_data['dip_features'] = g_data['Sequence'].apply(dipeptide_composition)\n",
    "g_data['phys_features'] = g_data['Sequence'].apply(avg_physicochemical_properties)\n",
    "\n",
    "print(\"After feature extraction, g_data will have 3 new columns for Amino Acid Composition, Physicochemical Properties, and Dipeptide Composition\")\n",
    "print(f\"Heres a sample of the matrix now:\\n\\n{g_data.head()}\")\n",
    "\n",
    "# Convert extracted features into DataFrames\n",
    "aa_features = pd.DataFrame(g_data['aa_features'].tolist())\n",
    "dip_features = pd.DataFrame(g_data['dip_features'].tolist())\n",
    "phys_features = pd.DataFrame(g_data['phys_features'].tolist())\n",
    "\n",
    "\n",
    "# Step 3: Combine features\n",
    "# Merge occurrence features and all sequence-derived features\n",
    "combined_data = pd.concat([\n",
    "    occur_data.iloc[:, 1:],  # Occurrence features\n",
    "    aa_features,             # Amino acid composition\n",
    "    phys_features,           # Physicochemical properties\n",
    "    dip_features             # Dipeptide composition\n",
    "], axis=1)\n",
    "\n",
    "print(f\"\\nNext we extract these features, take them out of g_data, and put them into their own matrix\\n\")\n",
    "\n",
    "print(f\"Recall that there are 523 proteins and 449 different feature combinations,\\n thus the matrix is size {combined_data.shape}\")\n",
    "\n",
    "\n",
    "# Add labels and encode them numerically\n",
    "# Extract the fold information\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(g_data['Fold'])  # Now this will get Fold1, Fold2, etc.\n",
    "fold_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "print(f\"\\nRecall that there are 4 folds in g_data\\nLabel mapping: {fold_mapping}\\n\")\n",
    "\n",
    "\n",
    "# Step 4: Normalize and select features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(combined_data)\n",
    "\n",
    "\n",
    "# Note: These train/test split operations have been moved after feature selection\n",
    "# Feature selection using Random Forest\n",
    "print(\"Performing feature selection...\")\n",
    "selector = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "    threshold=\"median\"\n",
    ")\n",
    "selector.fit(normalized_features, labels)\n",
    "selected_features = selector.transform(normalized_features)\n",
    "print(f\"Selected {selected_features.shape[1]} out of {normalized_features.shape[1]} features\")\n",
    "\n",
    "print(f\"We use Random Forest Classifier to identify these features, note that the matrix is now {selected_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea2636-4aa2-4d88-b90f-8644a0ec3aea",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This step is a jump in complexity but it is ultimately just basic feature extraction. To explain the process, our CSV g_data starts sa list of 523 protein sequences and their respective folds. We read these sequences and extrapolate certain information about them; in our case it is simply their Amino Acid struture (Single Occurances), DiPeptide Structure (Pair Occurances), and Physiochemical Properties (Attributes)\n",
    "\n",
    "* Example: For a sequence \"ACDKLLM\", the amino acid composition would be:\n",
    "* {'A': 0.143, 'C': 0.143, 'D': 0.143, 'K': 0.143, 'L': 0.286, 'M': 0.143, ...} (with zeros for all other amino acids not present)\n",
    "\n",
    "* Example: For a sequence \"ACDKLLM\", the dipeptides are \"AC\", \"CD\", \"DK\", \"KL\", \"LL\", \"LM\"\n",
    "* Each dipeptide frequency would be 1/6 = 0.167 (with zeros for all other combinations)\n",
    "  \n",
    "### Physicochemical Properties\n",
    "Using the attributes.csv file, we calculated the average value of 9 different physicochemical properties for each protein sequence. These properties include hydrophobicity, polarity, charge, and other biochemical characteristics that influence protein folding and function.\n",
    "\n",
    "### Feature Combination and Selection\n",
    "\n",
    "The next critical step was to combine all extracted features into a unified feature matrix:\n",
    "\n",
    "```\n",
    "Recall that there are 523 proteins and 449 different feature combinations, thus the matrix is size (523, 449)\n",
    "```\n",
    "\n",
    "The high-dimensional matrix contains:\n",
    "- 20 amino acid composition features\n",
    "- 400 dipeptide composition features \n",
    "- 9 averaged physicochemical properties\n",
    "- 20 occurrence features from the original `occur.csv` file\n",
    "\n",
    "To improve model performance and reduce overfitting, we applied feature selection using a Random Forest classifier, which identified the most informative features:\n",
    "\n",
    "```\n",
    "Selected 225 out of 449 features\n",
    "```\n",
    "\n",
    "This dimensionality reduction cut our feature space nearly in half while preserving the most predictive attributes, significantly improving both model performance and training efficiency.\n",
    "\n",
    "The resulting feature matrix (523 rows × 225 columns) provides a comprehensive numerical representation of the protein sequences, capturing compositional, sequential, and physicochemical information relevant to cellular localization prediction.\n",
    "\n",
    "# Step 2.5: Split Data into Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52205e63-6861-46e5-a8d2-b9e3764dc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split the data into training and testing sets (with stratification)\n",
    "X_train_main, X_test_independent, y_train_main, y_test_independent = train_test_split(\n",
    "    selected_features,        # Use selected features instead of normalized_features\n",
    "    labels,\n",
    "    test_size=0.2,          # 20% for independent testing\n",
    "    random_state=42,\n",
    "    stratify=labels         # ensure balanced class distribution\n",
    ")\n",
    "\n",
    "# Second split: create validation set from training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_main,\n",
    "    y_train_main,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y_train_main\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb0c7e-2571-47ae-971d-e4237d73eed0",
   "metadata": {},
   "source": [
    "In this step, we did two things:\n",
    "- First we created an independent test set that would remain completely untouched during model development ***20% of data***\n",
    "- Second we created validation and training sets ***80% of remaining data**\n",
    "  - A training set (75% of X_train_main, or approximately 314 samples) for model fitting\n",
    "  - A validation set (25% of X_train_main, or approximately 104 samples) for hyperparameter tuning\n",
    "\n",
    "A suprisingly important function is that both splitting operations used stratification (stratify=labels and stratify=y_train_main), which makes sure that **the class distribution in the original dataset is preserved in all subsets (Folds).** \n",
    "\n",
    "This is particularly important because our dataset has four protein location classes (Folds) that may be imbalanced.\n",
    "If the original dataset contained:\n",
    "- 40% Fold1\n",
    "- 30% Fold2\n",
    "- 20% Fold3\n",
    "- 10% Fold4\n",
    "\n",
    "Then each subset (training, validation, and independent test) would **maintain these same proportions, preventing sampling bias** and ensuring that models are evaluated on properly representative data.\n",
    "\n",
    "# Step 3: Models; Hyperparameter Tuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b34d67-45ee-4bcf-8867-6b681a8d3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-------------------------------------K-Nearest Neighbors (KNN) with hyperparameter tuning-------------------------------------\n",
    "\"\"\"\n",
    "print(\"\\nTuning KNN hyperparameters...\")\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # p=1 is Manhattan distance, p=2 is Euclidean\n",
    "}\n",
    "knn = GridSearchCV(\n",
    "    KNeighborsClassifier(), \n",
    "    knn_params, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "knn.fit(X_train, y_train)\n",
    "print(f\"Best KNN parameters: {knn.best_params_}\")\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN Accuracy:\", round(accuracy_score(y_test, y_pred_knn), 2))\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------Support Vector Machine (SVM) with hyperparameter tuning-------------------------------------\n",
    "\"\"\"\n",
    "print(\"\\nTuning SVM hyperparameters...\")\n",
    "svm_params = {\n",
    "    'C': [10],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "svm = GridSearchCV(\n",
    "    SVC(probability=True), \n",
    "    svm_params, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "svm.fit(X_train, y_train)\n",
    "print(f\"Best SVM parameters: {svm.best_params_}\")\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"SVM Accuracy:\", round(accuracy_score(y_test, y_pred_svm), 2))\n",
    "print(classification_report(y_test, y_pred_svm, zero_division=0))\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------Random Forest with hyperparameter tuning-------------------------------------\n",
    "\"\"\"\n",
    "print(\"\\nTuning Random Forest hyperparameters...\")\n",
    "rf_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42), \n",
    "    rf_params, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "print(f\"Best Random Forest parameters: {rf.best_params_}\")\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", round(accuracy_score(y_test, y_pred_rf), 2))\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
    "\n",
    "\"\"\"\n",
    "Naïve Bayes with parameter exploration\n",
    "\"\"\"\n",
    "print(\"\\nTraining Naive Bayes model...\")\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"Naïve Bayes Accuracy:\", round(accuracy_score(y_test, y_pred_nb), 2))\n",
    "print(classification_report(y_test, y_pred_nb, zero_division=0))\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------Artificial Neural Network (ANN) with hyperparameter tuning-----------------------------------------\n",
    "\"\"\"\n",
    "print(\"\\nTuning Neural Network hyperparameters...\")\n",
    "ann_params = {\n",
    "    'hidden_layer_sizes': [(100, 50)],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [0.0001],\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "ann = GridSearchCV(\n",
    "    MLPClassifier(random_state=42),\n",
    "    ann_params,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # Using 3-fold to save time\n",
    "    scoring='accuracy'\n",
    ")\n",
    "ann.fit(X_train, y_train)\n",
    "print(f\"Best Neural Network parameters: {ann.best_params_}\")\n",
    "y_pred_ann = ann.predict(X_test)\n",
    "print(\"ANN Accuracy:\", round(accuracy_score(y_test, y_pred_ann), 2))\n",
    "print(classification_report(y_test, y_pred_ann, zero_division=0))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------Bagging Classifier-------------------------------------\n",
    "\"\"\"\n",
    "bagging = BaggingClassifier(estimator = KNeighborsClassifier(), n_estimators = 50, random_state = 42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print(\"Bagging Accuracy:\", round(accuracy_score(y_test, y_pred_bagging), 2))\n",
    "print(classification_report(y_test, y_pred_bagging, zero_division=0))\n",
    "# AdaBoost Classifier\n",
    "print(\"\\nTraining AdaBoost Classifier...\")\n",
    "ada = AdaBoostClassifier(\n",
    "    estimator=RandomForestClassifier(max_depth=3, random_state=42),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "print(\"AdaBoost Accuracy:\", round(accuracy_score(y_test, y_pred_ada), 2))\n",
    "print(classification_report(y_test, y_pred_ada, zero_division=0))\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "-------------------------------------Stacking Classifier-------------------------------------\n",
    "\"\"\"\n",
    "print(\"\\nTraining Stacking Classifier...\")\n",
    "estimators = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, kernel='rbf', random_state=42))\n",
    "]\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    cv=5,\n",
    "    stack_method='predict_proba'\n",
    ")\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", round(accuracy_score(y_test, y_pred_stacking), 2))\n",
    "print(classification_report(y_test, y_pred_stacking, zero_division=0))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------Voting Classifier-------------------------------------\n",
    "\"\"\"\n",
    "print(\"\\nTraining Voting Classifier...\")\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn', knn.best_estimator_),\n",
    "        ('rf', rf.best_estimator_),\n",
    "        ('svm', svm.best_estimator_),\n",
    "        ('nb', GaussianNB()),\n",
    "        ('ann', ann.best_estimator_),\n",
    "        ('ada', ada)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "voting.fit(X_train, y_train)\n",
    "y_pred_voting = voting.predict(X_test)\n",
    "print(\"Voting Classifier Accuracy:\", round(accuracy_score(y_test, y_pred_voting), 2))\n",
    "print(classification_report(y_test, y_pred_voting, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6274a-7d9b-4f91-b9d1-75ae8db976b2",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This step is obviously crucial, however, I think the code is self-explanatory. A key point in the project for this step was tuning the models and model specific parameters to boost the accuracy. We did see some improvements, with SVM reaching 75% accuracy, a relatively big improvement over the previous 65%. As you can see the ideal params are \n",
    "```\n",
    "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "```\n",
    "These parameters indicate that a radial basis function kernel with moderately high regularization strength performed best for protein localization prediction, effectively handling the non-linear relationships in our feature space. This being said, we did not utilize much methodology to achieve this improvement. But simply tweaking parameters to test them is always a great idea and with more time and rigor this could likely be even higher.\n",
    "\n",
    "### Models Used\n",
    "- KNN\n",
    "For KNN, we identified optimal parameters of 9 neighbors with uniform weighting and Euclidean distance (p=2), achieving 70% accuracy. This suggests that protein localization patterns are best captured by examining several nearby reference proteins.\n",
    "- SVM\n",
    "- Random Forest\n",
    "- Naive Bayes\n",
    "- ANN\n",
    "Our ANN architecture with hidden layer sizes of (100, 50), ReLU activation, and adaptive learning rate yielded 70% accuracy, showing strong performance in capturing complex feature relationships.\n",
    "\n",
    "### Here are our ensemble Methods\n",
    "- Bagging (66% accuracy): Used multiple KNN classifiers on bootstrapped samples\n",
    "- AdaBoost (68% accuracy): Sequentially focused on misclassified proteins\n",
    "- Stacking\n",
    "Our second-best model at 74% accuracy was a stacking ensemble that combined KNN, Random Forest, and SVM with a Random Forest meta-learner. This approach leveraged the strengths of multiple algorithms to improve overall prediction reliability.\n",
    "- Voting Classifier (70% accuracy): Combined predictions from our six best models\n",
    "\n",
    "# Step 4: Results, Interpretation, Cross-Validation\n",
    "\n",
    "To ensure robust performance estimation, we employed **both stratified k-fold cross-validation on the training data and evaluation on a completely independent test set.**\n",
    "\n",
    "- Random Forest Cross-Validation Balanced Accuracy: 0.52\n",
    "- SVM Cross-Validation Balanced Accuracy: 0.56\n",
    "- Voting Cross-Validation Balanced Accuracy: 0.56\n",
    "\n",
    "The balanced accuracy scores account for potential class imbalance, providing a more realistic performance measure. These cross-validation results highlight that while SVM and Voting classifiers showed strong performance, they still faced challenges with underrepresented classes.\n",
    "\n",
    "### When evaluated on the completely independent test set, our models showed consistency in their performance:\n",
    "- K-Nearest Neighbors: 0.67\n",
    "- Support Vector Machine: 0.69\n",
    "- Random Forest: 0.64\n",
    "- Naive Bayes: 0.64\n",
    "- Artificial Neural Network: 0.70\n",
    "- Bagging: 0.66\n",
    "\n",
    "**The ANN performed best on independent data, demonstrating strong generalization capability, closely followed by SVM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6c0fd-850b-4f3a-9fd1-32a73a54f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming cross-validation with stratified k-fold...\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"We only need to cross-validate our best models to save time and energy...\")\n",
    "\n",
    "cv_scores_rf = cross_val_score(rf, selected_features, labels, cv=cv, scoring='balanced_accuracy')\n",
    "print(\"Random Forest Cross-Validation Balanced Accuracy:\", round(cv_scores_rf.mean(), 2))\n",
    "\n",
    "cv_scores_svm = cross_val_score(svm, selected_features, labels, cv=cv, scoring='balanced_accuracy')\n",
    "print(\"SVM Cross-Validation Balanced Accuracy:\", round(cv_scores_svm.mean(), 2))\n",
    "\n",
    "cv_scores_voting = cross_val_score(voting, selected_features, labels, cv=cv, scoring='balanced_accuracy')\n",
    "print(\"Voting Cross-Validation Balanced Accuracy:\", round(cv_scores_voting.mean(), 2))\n",
    "\n",
    "\n",
    "# Evaluate all models on the independent test set\n",
    "def evaluate_model(model, model_name):\n",
    "    y_pred = model.predict(X_test_independent)\n",
    "    accuracy = accuracy_score(y_test_independent, y_pred)\n",
    "    report = classification_report(y_test_independent, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance on Independent Test Set:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Detailed Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Evaluate each model\n",
    "independent_results = {\n",
    "    'KNN': evaluate_model(knn, \"K-Nearest Neighbors\"),\n",
    "    'SVM': evaluate_model(svm, \"Support Vector Machine\"),\n",
    "    'RF': evaluate_model(rf, \"Random Forest\"),\n",
    "    'NB': evaluate_model(nb, \"Naive Bayes\"),\n",
    "    'ANN': evaluate_model(ann, \"Artificial Neural Network\"),\n",
    "    'Bagging': evaluate_model(bagging, \"Bagging\")\n",
    "}\n",
    "\n",
    "# Compare model performances\n",
    "print(\"\\nModel Performance Comparison on Independent Test Set:\")\n",
    "for model_name, accuracy in independent_results.items():\n",
    "    print(f\"{model_name}: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Save processed data\n",
    "processed_data = pd.concat([pd.DataFrame(normalized_features), pd.Series(labels, name='Label')], axis=1)\n",
    "processed_data.to_csv(\"Data/processed_data.csv\", index=False)\n",
    "\n",
    "\n",
    "# Print summary of best models (based on test accuracy)\n",
    "print(\"\\n=== Model Accuracy Summary ===\")\n",
    "model_accuracies = {\n",
    "    \"KNN\": round(accuracy_score(y_test, y_pred_knn), 2),\n",
    "    \"SVM\": round(accuracy_score(y_test, y_pred_svm), 2),\n",
    "    \"Random Forest\": round(accuracy_score(y_test, y_pred_rf), 2),\n",
    "    \"Naive Bayes\": round(accuracy_score(y_test, y_pred_nb), 2),\n",
    "    \"ANN\": round(accuracy_score(y_test, y_pred_ann), 2),\n",
    "    \"Bagging\": round(accuracy_score(y_test, y_pred_bagging), 2),\n",
    "    \"AdaBoost\": round(accuracy_score(y_test, y_pred_ada), 2),\n",
    "    \"Stacking\": round(accuracy_score(y_test, y_pred_stacking), 2),\n",
    "    \"Voting\": round(accuracy_score(y_test, y_pred_voting), 2)\n",
    "}\n",
    "\n",
    "\n",
    "# Sort models by accuracy\n",
    "sorted_models = sorted(model_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Print models in order of performance\n",
    "for model_name, accuracy in sorted_models:\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"\\n=== Accuracy Improvement Summary ===\")\n",
    "print(\"Original KNN Accuracy: 0.70 → New KNN Accuracy: \" + str(model_accuracies[\"KNN\"]))\n",
    "print(\"Original SVM Accuracy: 0.67 → New SVM Accuracy: \" + str(model_accuracies[\"SVM\"]))\n",
    "print(\"Original Random Forest Accuracy: 0.71 → New Random Forest Accuracy: \" + str(model_accuracies[\"Random Forest\"]))\n",
    "print(\"Original Naive Bayes Accuracy: 0.64 → New Naive Bayes Accuracy: \" + str(model_accuracies[\"Naive Bayes\"]))\n",
    "print(\"Original ANN Accuracy: 0.68 → New ANN Accuracy: \" + str(model_accuracies[\"ANN\"]))\n",
    "print(\"Original Bagging Accuracy: 0.68 → New Bagging Accuracy: \" + str(model_accuracies[\"Bagging\"]))\n",
    "\n",
    "print(\"\\nBest Model: \" + sorted_models[0][0] + \" with accuracy \" + str(sorted_models[0][1]))\n",
    "print(\"Average accuracy improvement: \" + str(round(((model_accuracies[\"KNN\"] + model_accuracies[\"SVM\"] + model_accuracies[\"Random Forest\"] + model_accuracies[\"Naive Bayes\"] + model_accuracies[\"ANN\"] + model_accuracies[\"Bagging\"])/6 - 0.68), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf550b4-b3be-4406-ab95-53decd437749",
   "metadata": {},
   "source": [
    "# Final Thoughts and Conclusions\n",
    "\n",
    "The detailed classification reports revealed important patterns across models:\n",
    "\n",
    "1. Class Imbalance Issues: All models struggled with class 1 (likely the minority class), often showing zero precision and recall. This indicates insufficient training examples for this location.\n",
    "2. Strong Performance for Class 2: Most models exhibited high recall (up to 93%) for class 2, suggesting this subcellular location has distinctive features.\n",
    "3. Precision-Recall Trade-offs: Models generally showed imbalances between precision and recall. For example, SVM on the validation set achieved high precision for class 2 (0.80) and class 0 (0.73), but lower for class 3 (0.70).\n",
    "4. Weighted vs. Macro Averages: The difference between weighted and macro average F1-scores (SVM: weighted=0.73 vs macro=0.56) confirms the impact of class imbalance on overall metrics.\n",
    "\n",
    "Our systematic approach resulted in meaningful improvements:\n",
    "\n",
    "    SVM improved from 67% to 75% accuracy\n",
    "    Naive Bayes improved from 64% to 68% accuracy\n",
    "    ANN improved from 68% to 70% accuracy\n",
    "\n",
    "While Random Forest and Bagging showed slight decreases in performance, the average improvement across all models was +0.01, demonstrating the value of our feature engineering and hyperparameter optimization efforts.\n",
    "\n",
    "# Takeaways\n",
    "\n",
    "This project ultimately shows both the power and limitations of machine learning in bioinformatics. If we were to takeaway some main points to apply to future work in both ML and Biological Data.\n",
    "\n",
    "1. Choosing Features is hugely important. Although we did not experiment with the actual effects of this, a considerable amount of the process is simply cleaning data and identifying actionable features. Organizing the data by hand like this puts less work on the model, so it can work with a cleaner data pool, be more efficient, and hopefully recognize meaningful patterns easier (essentially we removed columns with the most 0s, some decisions were more complex than this but we used scikit learn to handle this).\n",
    "2. Class Imbalance Challenges: The consistent difficulty in classifying proteins from the minority class highlights a fundamental challenge in biological datasets. Future work should focus on specialized techniques for imbalanced data, such as oversampling or class-weighted loss functions.\n",
    "3. Model Selection Trade-offs: While SVM performed best on validation data (75%), ANN showed superior generalization on the independent test set (70%), suggesting that model selection should consider both validation performance and generalization capability.\n",
    "4. Ensemble Benefits: Stacking and voting classifiers demonstrated strong performance, re-enforcing the value of combining multiple modeling approaches when tackling complex (biological) classification problems. Although you should generally start simple with new problems, its evident in this case that a combination does achieve great results, and it most cases will."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
